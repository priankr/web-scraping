{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Web scraping is used for extracting data from websites. \n",
    "\n",
    "The process begins by inspecting the website's html and identifying the elements that contain the data we are interested in. The data can be located in different types of html elements such as div, span etc. and depending on how it is organized we approach it differently.  \n",
    "\n",
    "- Grouped Data (contact details, product details etc.) will be stored in similar himl elements. We will have to loop over these similar elements and extract the desired information. \n",
    "- Ungrouped Data may be stored in an html element that is shared across other pieces of data. If there is no unique class or id for the desired data, we can store all the instances of this html element in a list or data frame and use indexing to access the desired information.\n",
    "\n",
    "#### Below are examples of web scraping on different types of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Result Data\n",
    "\n",
    "### Indeed Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Indeed search for Business Analyst roles in Toronto\n",
    "page = requests.get(\"https://ca.indeed.com/jobs?q=Business+Analyst&l=Toronto%2C+ON\")\n",
    "\n",
    "#Checking to see what response code we get from the page we requested\n",
    "#The HTTP 200 OK success status response code indicates that the request has succeeded\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the BeautifulSoup library to parse this document\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Category Business Analyst</td>\n",
       "      <td>Canadian Tire</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business management analyst</td>\n",
       "      <td>MSG GLOBAL SOLUTIONS CANADA INC</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Analyst, Commercial</td>\n",
       "      <td>Canada Goose Inc.</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>ThreePDS Inc</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Intern, Business Analyst</td>\n",
       "      <td>Equitable Bank</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Junior Business Analyst (6 month contract)</td>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Business Analyst / QA</td>\n",
       "      <td>MEDCAN</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Support Analyst</td>\n",
       "      <td>BMO Financial Group</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jr. / Int. Business Analyst</td>\n",
       "      <td>JLL</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Distributel</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>business systems analyst</td>\n",
       "      <td>Lifanov Consulting Inc.</td>\n",
       "      <td>Concord, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Datavail</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business management analyst</td>\n",
       "      <td>ShoreWise Consulting LLC</td>\n",
       "      <td>Mississauga, ON•Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Junior Business Analyst</td>\n",
       "      <td>DLT Labs</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Business Analyst - Business Management</td>\n",
       "      <td>BMO Financial Group</td>\n",
       "      <td>Toronto, ON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Title  \\\n",
       "0                    Category Business Analyst   \n",
       "1                  business management analyst   \n",
       "2                 Business Analyst, Commercial   \n",
       "3                             Business Analyst   \n",
       "4                     Intern, Business Analyst   \n",
       "5   Junior Business Analyst (6 month contract)   \n",
       "6                        Business Analyst / QA   \n",
       "7                     Business Support Analyst   \n",
       "8                  Jr. / Int. Business Analyst   \n",
       "9                             Business Analyst   \n",
       "10                    business systems analyst   \n",
       "11                            Business Analyst   \n",
       "12                 business management analyst   \n",
       "13                     Junior Business Analyst   \n",
       "14      Business Analyst - Business Management   \n",
       "\n",
       "                       Company Name                Location  \n",
       "0                     Canadian Tire             Toronto, ON  \n",
       "1   MSG GLOBAL SOLUTIONS CANADA INC             Toronto, ON  \n",
       "2                 Canada Goose Inc.             Toronto, ON  \n",
       "3                      ThreePDS Inc             Toronto, ON  \n",
       "4                    Equitable Bank             Toronto, ON  \n",
       "5                               H&M             Toronto, ON  \n",
       "6                            MEDCAN             Toronto, ON  \n",
       "7               BMO Financial Group             Toronto, ON  \n",
       "8                               JLL             Toronto, ON  \n",
       "9                       Distributel             Toronto, ON  \n",
       "10          Lifanov Consulting Inc.             Concord, ON  \n",
       "11                         Datavail             Toronto, ON  \n",
       "12         ShoreWise Consulting LLC  Mississauga, ON•Remote  \n",
       "13                         DLT Labs             Toronto, ON  \n",
       "14              BMO Financial Group             Toronto, ON  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the find_all method to search for items by class or by id\n",
    "jobs_html = soup.find_all('td', class_=\"resultContent\")\n",
    "\n",
    "#Creating an empty dataframe with a column to store all values we are interested in\n",
    "jobs_df = pd.DataFrame(columns=['Job Title', 'Company Name', 'Location'])\n",
    "\n",
    "for jobs in jobs_html:\n",
    "    #Some jobs have a label called \"new\" to indicate a new posting. We need to check for this to identify which span element contains the job title\n",
    "    if (jobs.find_all('span')[0]).text.strip() == \"new\":\n",
    "        job_title_html = jobs.find_all('span')[1]\n",
    "    else:\n",
    "        job_title_html = jobs.find_all('span')[0]\n",
    "    \n",
    "    company_name_html = jobs.find('span', class_=\"companyName\")\n",
    "    location_html = jobs.find('div', class_=\"companyLocation\")\n",
    "   \n",
    "    job_title = job_title_html.text.strip()\n",
    "    company_name = company_name_html.text.strip()\n",
    "    location = location_html.text.strip()\n",
    "    \n",
    "    df = {'Job Title':job_title, 'Company Name':company_name, 'Location':location}\n",
    "    \n",
    "    jobs_df = jobs_df.append(df, ignore_index = True)\n",
    "\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yelp Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Yelp search for Coffee Shops in Los Angeles\n",
    "page = requests.get(\"https://www.yelp.com/search?find_desc=Coffee+Shop&find_loc=Los+Angeles%2C+CA\")\n",
    "\n",
    "#Checking to see what response code we get from the page we requested\n",
    "#The HTTP 200 OK success status response code indicates that the request has succeeded\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the BeautifulSoup library to parse this document\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coffee Shop Name</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alibi Coffee</td>\n",
       "      <td>157</td>\n",
       "      <td>Larchmont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coffee Connection</td>\n",
       "      <td>626</td>\n",
       "      <td>Mar Vista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alchemist Coffee Project</td>\n",
       "      <td>1164</td>\n",
       "      <td>Wilshire Center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bungalow 40</td>\n",
       "      <td>87</td>\n",
       "      <td>Hollywood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coffee MCO</td>\n",
       "      <td>364</td>\n",
       "      <td>Pico-Union</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Coffee For Sasquatch</td>\n",
       "      <td>311</td>\n",
       "      <td>Hancock Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Document Coffee Bar</td>\n",
       "      <td>592</td>\n",
       "      <td>Koreatown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Stereoscope Coffee Company</td>\n",
       "      <td>48</td>\n",
       "      <td>Echo Park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Boxx Coffee Roasters</td>\n",
       "      <td>42</td>\n",
       "      <td>Arts District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>88</td>\n",
       "      <td>Fairfax</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coffee Shop Name Number of Reviews         Location\n",
       "0                Alibi Coffee               157        Larchmont\n",
       "1           Coffee Connection               626        Mar Vista\n",
       "2    Alchemist Coffee Project              1164  Wilshire Center\n",
       "3                 Bungalow 40                87        Hollywood\n",
       "4                  Coffee MCO               364       Pico-Union\n",
       "5        Coffee For Sasquatch               311     Hancock Park\n",
       "6         Document Coffee Bar               592        Koreatown\n",
       "7  Stereoscope Coffee Company                48        Echo Park\n",
       "8        Boxx Coffee Roasters                42    Arts District\n",
       "9                Neighborhood                88          Fairfax"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the find_all method to search for items by class or by id\n",
    "shops_html = soup.find_all('div', class_=\"arrange-unit__09f24__eFC_S arrange-unit-fill__09f24__1bMmp border-color--default__09f24__3Epto\")\n",
    "\n",
    "#Creating an empty dataframe with a column to store all values we are interested in\n",
    "shops_df = pd.DataFrame(columns=['Coffee Shop Name', 'Number of Reviews', 'Location'])\n",
    "\n",
    "for shop in shops_html:\n",
    "    #Extracting the desired html elements\n",
    "    shop_name_html = shop.find('a', class_=\"css-og60gk\")\n",
    "    number_of_reviews_html = shop.find('span', class_=\"reviewCount__09f24__3GsGY css-e81eai\")\n",
    "    location_html = (shop.find('p', class_=\"css-1j7sdmt\"))\n",
    "    \n",
    "    #We get an issue with some Nonetype objects appearing when we select the html elements. \n",
    "    #The if statement below allows us to avoid any Nonetype values \n",
    "    if None not in (shop_name_html, number_of_reviews_html, location_html):\n",
    "       \n",
    "        \n",
    "        #Extracting the text from the html elements\n",
    "        shop_name = shop_name_html.text.strip()\n",
    "        number_of_reviews = number_of_reviews_html.text.strip()\n",
    "        \n",
    "        #We need to use .find() a second time to access the <span> tag within the <p> tag\n",
    "        location = location_html.find('span', class_=\"css-e81eai\").text.strip()\n",
    "        \n",
    "        df = {'Coffee Shop Name':shop_name, 'Number of Reviews':number_of_reviews, 'Location':location}\n",
    "        \n",
    "        shops_df = shops_df.append(df, ignore_index = True)\n",
    "\n",
    "shops_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Data\n",
    "\n",
    "### IMDb Box Office Charts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMDb page with today's box office charts\n",
    "page = requests.get(\"https://www.imdb.com/chart/boxoffice/\")\n",
    "\n",
    "#Checking to see what response code we get from the page we requested\n",
    "#The HTTP 200 OK success status response code indicates that the request has succeeded\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the BeautifulSoup library to parse this document\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Weekend Earnings</th>\n",
       "      <th>Gross Earnings</th>\n",
       "      <th>Weeks in Theaters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Venom: Let There Be Carnage</td>\n",
       "      <td>$90.0M</td>\n",
       "      <td>$90.0M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Addams Family 2</td>\n",
       "      <td>$17.3M</td>\n",
       "      <td>$17.3M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shang-Chi and the Legend of the Ten Rings</td>\n",
       "      <td>$6.1M</td>\n",
       "      <td>$206.2M</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Many Saints of Newark</td>\n",
       "      <td>$4.7M</td>\n",
       "      <td>$4.7M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear Evan Hansen</td>\n",
       "      <td>$2.5M</td>\n",
       "      <td>$11.8M</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Free Guy</td>\n",
       "      <td>$2.3M</td>\n",
       "      <td>$117.6M</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Candyman</td>\n",
       "      <td>$1.3M</td>\n",
       "      <td>$58.9M</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jungle Cruise</td>\n",
       "      <td>$703K</td>\n",
       "      <td>$116.1M</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chal Mera Putt 3</td>\n",
       "      <td>$644K</td>\n",
       "      <td>$644K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Jesus Music</td>\n",
       "      <td>$549K</td>\n",
       "      <td>$549K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title Weekend Earnings Gross Earnings  \\\n",
       "0                Venom: Let There Be Carnage           $90.0M         $90.0M   \n",
       "1                        The Addams Family 2           $17.3M         $17.3M   \n",
       "2  Shang-Chi and the Legend of the Ten Rings            $6.1M        $206.2M   \n",
       "3                  The Many Saints of Newark            $4.7M          $4.7M   \n",
       "4                           Dear Evan Hansen            $2.5M         $11.8M   \n",
       "5                                   Free Guy            $2.3M        $117.6M   \n",
       "6                                   Candyman            $1.3M         $58.9M   \n",
       "7                              Jungle Cruise            $703K        $116.1M   \n",
       "8                           Chal Mera Putt 3            $644K          $644K   \n",
       "9                            The Jesus Music            $549K          $549K   \n",
       "\n",
       "  Weeks in Theaters  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 5  \n",
       "3                 1  \n",
       "4                 2  \n",
       "5                 8  \n",
       "6                 6  \n",
       "7                10  \n",
       "8                 1  \n",
       "9                 1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the find_all method to search for items by class or by id\n",
    "imdb_html = soup.find_all('tr')\n",
    "\n",
    "#Creating an empty dataframe with a column to store all values we are interested in\n",
    "imdb_df = pd.DataFrame(columns=['Title', 'Weekend Earnings', 'Gross Earnings', 'Weeks in Theaters'])\n",
    "\n",
    "for movie in imdb_html:\n",
    "    #Extracting the desired html elements\n",
    "    title_html = movie.find('td', class_=\"titleColumn\")\n",
    "    weekend_html = movie.find('td', class_=\"ratingColumn\")\n",
    "    gross_html = movie.find('span', class_=\"secondaryInfo\")\n",
    "    weeks_html = movie.find('td', class_=\"weeksColumn\")\n",
    "    \n",
    "    #We get an issue with some Nonetype objects appearing when we select the html elements. \n",
    "    #The if statement below allows us to avoid any Nonetype values \n",
    "    if None not in (title_html, weekend_html, gross_html,weeks_html):\n",
    "        \n",
    "        #Extracting the text from the html elements\n",
    "        title = title_html.text.strip()\n",
    "        weekend = weekend_html.text.strip()\n",
    "        gross =  gross_html.text.strip()\n",
    "        weeks = weeks_html.text.strip()\n",
    "\n",
    "        df = {'Title':title, 'Weekend Earnings':weekend, 'Gross Earnings':gross, 'Weeks in Theaters':weeks}\n",
    "\n",
    "        imdb_df = imdb_df.append(df, ignore_index = True)\n",
    "\n",
    "imdb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Data\n",
    "\n",
    "### Wikipedia Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Wikipedia page on Televisions\n",
    "page = requests.get(\"https://en.wikipedia.org/wiki/Television\")\n",
    "\n",
    "#Checking to see what response code we get from the page we requested\n",
    "#The HTTP 200 OK success status response code indicates that the request has succeeded\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can use the BeautifulSoup library to parse this document\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Television, sometimes shortened to TV or telly, is a telecommunication medium used for transmitting moving images in monochrome (black and white), or in color, and in two or three dimensions and sound. The term can refer to a television set, a television show, or the medium of television transmission. Television is a mass medium for advertising, entertainment, news, and sports.',\n",
       " 'Television became available in crude experimental forms in the late 1920s, but it would still be several years before the new technology would be marketed to consumers. After World War II, an improved form of black-and-white television broadcasting became popular in the United Kingdom and United States, and television sets became commonplace in homes, businesses, and institutions. During the 1950s, television was the primary medium for influencing public opinion.[1] In the mid-1960s, color broadcasting was introduced in the U.S. and most other developed countries. The availability of various types of archival storage media such as Betamax and VHS tapes, high-capacity hard disk drives, DVDs, flash drives, high-definition Blu-ray Discs, and cloud digital video recorders has enabled viewers to watch pre-recorded material—such as movies—at home on their own time schedule. For many reasons, especially the convenience of remote retrieval, the storage of television and video programming now also occurs on the cloud (such as the video on demand service by Netflix). At the end of the first decade of the 2000s, digital television transmissions greatly increased in popularity. Another development was the move from standard-definition television (SDTV) (576i, with 576 interlaced lines of resolution and 480i) to high-definition television (HDTV), which provides a resolution that is substantially higher. HDTV may be transmitted in different formats: 1080p, 1080i and 720p. Since 2010, with the invention of smart television, Internet television has increased the availability of television programs and movies via the Internet through streaming video services such as Netflix, Amazon Video, iPlayer and Hulu.',\n",
       " \"In 2013, 79% of the world's households owned a television set.[2] The replacement of earlier bulky, high-voltage cathode ray tube (CRT) screen displays with compact, energy-efficient, flat-panel alternative technologies such as LCDs (both fluorescent-backlit and LED), OLED displays, and plasma displays was a hardware revolution that began with computer monitors in the late 1990s. Most television sets sold in the 2000s were flat-panel, mainly LEDs. Major manufacturers announced the discontinuation of CRT, DLP, plasma, and even fluorescent-backlit LCDs by the mid-2010s.[3][4] In the near future, LEDs are expected to be gradually replaced by OLEDs.[5] Also, major manufacturers have announced that they will increasingly produce smart TVs in the mid-2010s.[6][7][8] Smart TVs with integrated Internet and Web 2.0 functions became the dominant form of television by the late 2010s.[9]\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use the find_all method to search for items by class or by id\n",
    "tvs_html = soup.find_all('p')\n",
    "\n",
    "#Creating an empty list to store all values we are interested in\n",
    "tv_wiki = []\n",
    "\n",
    "for tv in tvs_html:\n",
    "    tv_wiki.append(tv.text.strip())    \n",
    "\n",
    "#Removing any empty strings\n",
    "tv_wiki.remove('')\n",
    "\n",
    "#See the first three paragraphs\n",
    "tv_wiki[0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
